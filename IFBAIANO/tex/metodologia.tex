
%VERIFICAR SE HÁ UMA PADRONIZAÇÃO DE DISTANCIA.

%

Neste capítulo, serão apresentadas todas as ferramentas e os procedimentos utilizados para a construção do modelo computacional de reconhecimento e classificação oócitos bovinos.

Primeiramente, os oócitos foram visualizados através de instrumentos de aproximação por conta de seu tamanho microscópico e as suas imagens foram capturadas e armazenadas. Em seguida, as imagens captadas são pré-processadas para a retirada de ruídos e padronização de camadas; processadas em uma rede neural para reconhecer as regiões onde se encontram os oócitos; construção do modelo para classificá-los; e, finalmente, um modelo final que une essas duas funcionalidades. Esse processo pode ser visualizado na figura \ref{fig:processo} e será descrito com mais detalhes nas seções seguintes.

\begin{figure}[H]
	\centering
	\caption{Demonstração das Etapas de Construção do Modelo}
	\includegraphics[width=0.9\textwidth]{images/ia/processo6.png}
	\caption*{\textbf{Fonte: Elaboração própria}}
	\label{fig:processo}
\end{figure}

\section{Visualização e Coleta}

Os oócitos utilizadas neste trabalho foram fornecidas pela empresa parceira BioInova \cite{bioinnova2024}. Ela possui experiência com produções \textit{in vitro} desde 2019 e, por conta disso, possui um vasto \textit{dataset} de oócitos que será necessário para realizar o processo de aprendizado do sistema .

A visualização e captura das imagens são feitas utilizando um instrumento de aproximação microscópico. Ele é demonstrado na Figura \ref{fig:lupa}

\begin{figure}[H]
	\centering
	\caption{Demonstração das componentes de um Microscópio Estereoscópio}
	\includegraphics[width=0.8\textwidth]{images/ferramentas/lupa.png}
	\caption*{\textbf{Fonte: \citeonline{gomes2005}.}} 
	\label{fig:lupa}
\end{figure}

Ele é equipado com uma câmera, o que permite a coletada das imagens de maneira apropriada. Essa é composta por um conjunto óptico de três câmeras, disponíveis num celular Samsung Galaxy s20 fe, que segundo o fabricante, é composta  12, 64 e 12 megapixels (MP) e aberturas de f1.8, f2.0 e f2.2, respectivamente (SAMSUNG, 2024).

\section{Pré-processamento}

Nessa seção, todas as etapas necessárias para preparar as condições mínicas necessárias para o desenvolvimento do modelo de identificação e classificação de oócitos serão abordadas. 

\subsection{OpenCV}
O pré-processamento consiste em corrigir aspectos ruidosos nas imagens, tais como: sujeiras, áreas ofuscadas, dentre outros. Essas correções podem ser radiométricas ou geométricas \cite{CHAKI2019} e são realizadas através da biblioteca OpenCV e seus métodos.

Algumas imagens passaram por uma correção radiométrica \cite{CHAKI2019}. Esse tipo de problema surge quando há um mal posicionamento do objeto capturado diante da luz ou falta de calibração adequada nos sensores. Isso faz com que alguns \textit{pixels} da imagem não sejam constituídos, ou seja, será necessário reconstituí-los de forma artificial através dos \textit{pixels} mais próximos como referência \cite{CHAKI2019}. Para tratar esse tipo de problema, os fundamentos utilizados são equalização de histograma e conversão de espaço de cores\ \cite{his} . 

Houve também casos em que movimentos durante o processo de captura e/ou lentes distorcidas no dispositivo de captação ocasionam um posicionamento distorcido de determinados \textit{pixels} da imagem \cite{CHAKI2019}. Para resolver isso, foi necessário reposicionar os \textit{pixels} que foram desvirtuados através das técnicas de transformações geométrica da OpenCV, que são: correção de distorção de lente, transformação de perspectiva, e transformação afim \cite{geo}. 

Para ajustes na iluminação, utilizou-se filtros de gradiente e equalizações de histograma, que servem para calibrar a regularidade de intensidade de \textit{pixels} \cite{KRIG2014}. 

Por fim, houve a necessidade de realizar ajustes relacionados ao foco de determinadas regiões da imagem captada. Por exemplo: se alguma região de interesse estiver desfocada ou se alguma região irrelevante estiver com muito foco, ambas essas situações precisarão ser reajustadas para que o processamento ocorra adequadamente \cite{KRIG2014}. 

\subsection{LabelMe}
O \textit{LabelMe} também apresentou-se como uma eficiente tecnologia para pré-processamento tendo em vista sua praticidade em carregar \textit{datasets}, opção para desenhar os círculos nas imagens e geração dos JSONs que contém os dados pré-processados \cite{russell2008labelme}. 


Um exemplo de imagem pré-processada pode ser visualizado na Figura \ref{fig:imagempre}.


\begin{figure}[H]
	\centering
	\caption{Imagem pré-processada}
	\includegraphics[width=0.8\textwidth]{images/ia/imagempre.png}
	\caption*{\textbf{Fonte: Elaboração Própria.}}
	\label{fig:imagempre}
\end{figure}


\section{Construção do Modelo de Identificação}
Com o conjunto de imagens completamente pré-processado, foi possível utilizar o Detectron2, que de acordo com \cite{Lad2024Detectron2}, é um \textit{framework} para diversos algoritmos de detecção de objetos e, entre eles, encontra-se o Mask R-CNN.  

Logo após, um modelo de aprendizado de máquina para identificar oócitos bovinos foi gerado com o Detectron2. A arquitetura desse modelo está representada na Figura \ref{fig:arquitetura}

\begin{figure}[H]
	\centering
	\caption{Arquitetura do Modelo de Aprendizado de Máquina para Identificação de Oócitos}
	\includegraphics[width=0.8\textwidth]{images/ia/arquitetura2.png}
	\caption*{\textbf{Fonte: Elaboração Própria.}} 
	\label{fig:arquitetura}
\end{figure}

Percebe-se uma arquitetura baseada no \textit{Mask R-CNN} utilizado pelo \textit{Detectron2} e adaptada especificamente para detecção e segmentação de oócitos bovinos.

Essa rede é composta por três módulos principais:


\begin{itemize}
	\item \textbf{Backbone (ResNet + FPN)}: as imagens dos oócitos foram processadas e suas características, extraídas. A \textit{Feature Pyramid Network} (FPN) foi responsável por combinar informações em múltiplas escalas (fpnlateral2 – 5) com convoluções de 256 canais, algo que permitiu detectar oócitos de diferentes tamanhos e contrastes;
	
	\item \textbf{\textit{Region Proposal Network} (RPN)}: aqui, regiões de interesse foram geradas através de probabiliades de cada região conter um objeto de interesse;
	
	\item \textbf{ROI Heads (Box Head e Mask Head)}: as propostas geradas na etapa anterior foram refinadas através de classificações e ajustes das caixas delimitadoras dos oócitos.
	
\end{itemize}

Logo após, houve a construção do modelo de identificação com os conjuntos de nome \textit{oocitosTrain} e \textit{oocitosVal} configurados para 1 classe (oócito) e com 1000 iterações.

Com o modelo para identificar oócitos treinado, tornou-se possível desenvolver a etapa de classificação. Pode-se averiguar o funcionamento de modelo de identificação na Figura \ref{fig:entradaEsaida}

\begin{figure}[H]
	\centering
	\caption{Imagem de Entrada e Saída no Modelo de Identificação de Oócitos}
	\includegraphics[width=0.8\textwidth]{images/ia/saida2.png}
	\caption*{\textbf{Fonte: Elaboração Própria.}} 
	\label{fig:entradaEsaida}
\end{figure}

Para que esse modelo pudesse ser treinamento corretamente, foi utilizada uma proporção de 80\% da base de dados para treinamento e 20\% para validação, que é uma divisão padrão.



Após a finalização dessa etapa, tornou-se necessário avaliar a eficiência do modelo de identificação. Com esse intuito, o Detectron2 utiliza o método \textit{COCOEvaluator}.


\section{Construção do Modelo de Classificação}


 \section{Modelo Final}


