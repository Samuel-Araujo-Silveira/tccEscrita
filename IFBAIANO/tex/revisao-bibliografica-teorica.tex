Durante a evolução dos mamíferos, a necessidade de garantir a continuidade das espécies fez com que esses animais desenvolvessem e aprimorassem seus métodos reprodutivos. Essas reproduções acontecem através da união do gameta masculino, chamado de espermatozoide, com o gameta feminino, conhecido como oócito. Essa união origina um zigoto, que se divide uma série de vezes até gerar um embrião \cite{HAFEZ}.  

No entanto, a atualidade, junto com sua tecnologia, possui estratégias que facilitam e aprimoram todo esse processo, como métodos modernos de reprodução assistida. Dentre eles, existe a produção \textit{in vitro} de embriões (PIV), que garante uma série de benefícios para a reprodução.


\section{Produção \textit{in vitro}}
O processo de desenvolvimento dessa técnica originou-se entre 1877 e 1899. Nessa época, pesquisadores buscavam estabelecer estratégias que permitissem a manipulação de embriões. Isso resultou na primeira visualização da fecundação de um oócito de estrela do mar que, por sua vez, originou um zigoto. Com o passar das décadas, mais especificamente em 1959, houve o nascimento do primeiro coelho gerado a partir da técnica de PIV  \cite{MELLO}.

De acordo com \citeonline{MELLO}, a PIV é uma biotécnica cujo objetivo é explorar o potencial genético de fêmeas bovinas. Ela é estratificada nas seguintes etapas: coleta, maturação, fecundação e cultivo \textit{in vitro}.  Além do mais, segundo \citeonline{GOUVEIA}, a PIV é importante por conta de sua importância para estudos biotecnológicos e fundamentos comerciais. 

Conforme a \citeonline{EMBRAPA}, a PIV apresenta as seguintes vantagens:


\begin{adjustwidth}{4cm}{0cm} % Aumenta o recuo da margem esquerda para 4cm
	\fontsize{10}{12}\selectfont % Ajusta o tamanho do texto para 10 pontos
	Possibilita a utilização de bezerras pré-púberes, vacas em início de gestação, vacas com subfertilidade adquirida, vacas senis e vacas mortas acidentalmente; produção de cerca de 36 bezerros por ano a partir de uma única fêmea; avanço na multiplicação de fêmeas bovinas de interesse para a produção animal e para a conservação de raças de animais domésticos ameaçadas de extinção; facilita o uso e aprimoramento de técnicas avançadas de reprodução animal, como: clonagem; injeção intracitoplasmática de espermatozoides; e transgenia; permite otimizar o uso de sêmen de reprodutores alto valor genético e de sêmen sexado; permite a produção de embriões com grau de sangue e sexo definidos para atender a programas específicos de produção (leite e carne), em larga escala e com menor custo.
\end{adjustwidth}

Entre as etapas de coleta e maturação, precisa existir uma fase de classificação dos oócitos coletados
\cite{PENITENTE}. Isso é importante porque algumas células não possuem as propriedades necessárias para seguir em frente no processo e algumas são melhores que outras. 



\subsection{Classificação de Oócitos}
Os oócitos coletados precisam ser divididos em quatro categorias, de acordo com as propriedades das células do cumulus e do ooplasma \cite{PENITENTE}. Esse método de classificação foi desenvolvido por \citeonline{LEIBFRIED}.

De acordo com \citeonline{SPMRcumulus}, as células do cumulus, um dos fatores de classificação mencionados, envolvem o oócito e desempenham papéis essenciais como garantir a comunicação bidirecional e proteger o oócito. A estrutura dessas células está ilustrada na Figura \ref{fig:oocito}.

Além do mais, segundo \citeonline{ELSEVIERcitoplasma}, o ooplasma, que é o segundo fator de classificação, é apenas o citoplasma do oócito. Ele é um líquido viscoso, localizado dentro da membrana citoplasmática e armazena toda a estrutura interna da célula \cite{ELSEVIERcitoplasma}. Seu posicionamento está representada na Figura \ref{fig:oocito}.

\begin{figure}[H]
	\centering
	\caption{Representação dos componentes de um oócito}
	\includegraphics[width=0.6\textwidth]{images/oocitos.png}
	\caption*{\textbf{Fonte: Elaboração própria.}} 
	\label{fig:oocito}
\end{figure}

Por fim, de acordo com \citeonline{PENITENTE}, os oócitos viáveis são os de classificação I a III, enquanto os de classificação IV são desconsiderados. 

\subsubsection{Classificação I}
Nesta categoria, as células do cumulus ou células da granulosa precisam formar, no mínimo, mais de três camadas \cite{PENITENTE}. Enquanto isso, o ooplasma precisa possuir coloração marrom com granulações finas e homogêneas \cite{PENITENTE}, conforme ilustrado na Figura \ref{fig:oocitoexemplo}

\begin{figure}[H]
	\centering
	\caption{Representação de um oócito com mais de três camadas de células da granulosa}
	\includegraphics[width=0.6\textwidth]{images/oocito/figura2.png}
	\caption*{\textbf{Fonte: Elaboração própria.}} 
	\label{fig:oocitoexemplo}
\end{figure}

\subsubsection{Classificação II}
Nesta classificação, os oócitos possuem menos de 3 camadas de células da granulosa, enquanto o ooplasma possui granulações distribuídas heterogeneamente \cite{PENITENTE}, conforme ilustrado na Figura \ref{fig:oocito2}. 

\begin{figure}[H]
	\centering
	\caption{Representação de um oócito com menos de três camadas de células da granulosa e com ooplasma heterogêneo}
	\includegraphics[width=0.6\textwidth]{images/oocito/figura3.png}
	\caption*{\textbf{Fonte: Elaboração própria.}} 
	\label{fig:oocito2}
\end{figure}

\subsubsection{Classificação III}
Nesta classificação, os oócitos possuem camadas de células da granulosa. No entanto, há um espaço entre a membrana celular e a zona pelúcida \cite{PENITENTE}, conforme ilustrado na figura \ref{fig:oocito5}. 

\begin{figure}[H]
	\centering
	\caption{Representação dos componentes de um oócito com espaço entre as células da granulosa e a zona pelúcida}
	\includegraphics[width=0.6\textwidth]{images/oocito/figura04.png}
	\caption*{\textbf{Fonte: Elaboração própria.}} 
	\label{fig:oocito5}
\end{figure}

\subsubsection{Classificação IV}
Nesta classificação, os oócitos não possuem células da granulosa ou possuem citoplasma com cor e granulação fora do normal \cite{PENITENTE},  conforme a Figura \ref{fig:oocito6}. 

\begin{figure}[H]
	\centering
	\caption{Representação dos componentes de um oócito sem camadas de células da granulosa}
	\includegraphics[width=0.6\textwidth]{images/oocito/figura5.png}
	\caption*{\textbf{Fonte: Elaboração própria.}} 
	\label{fig:oocito6}
\end{figure}



\section{Visão Computacional}

As ciências da computação possuem um ramo de estudo chamado de visão computacional \cite{BALLARD}. Essa área visa aprimorar as capacidades computacionais  de compreensão e interpretação de conteúdos visuais \cite{BALLARD}. Isso permite a criação de sistemas robustos e inteligentes que podem ser utilizados em diversos campos do conhecimento humano. 

O processamento de imagens é o cerne da visão computacional. Ele tem como objetivo coletar das imagens os tipos de dados definidos como parâmetros, ou seja, os que serão utilizados pelo sistema. Finalizada essa etapa, acontece o procedimento de classificação de entidades presentes na imagem \cite{JAHNE}. Segundo \cite{JAHNE}, esse processamento pode ser estratificado em uma série de passos até o resultado final ser alcançado. Alguns desses passos são dispensáveis, mas outros não.

De acordo com \citeonline{JAHNE}, o primeiro passo deve ser o ato de aquisição de imagem, algo que pode ser feito através de câmeras digitais ou analógicas. No entanto, essa última forma torna obrigatório o processo de digitalização da imagem para que se torne apropriada para o processo. Logo em seguida, efetua-se o pré-processamento cujo objetivo é eliminar eventuais imperfeições das imagens coletadas. Com essas etapas finalizadas, o reconhecimento de objetos pode ser realizado através da extração de características.

\subsection{Processamento Digital de Imagens}

A explicação sobre o que é uma imagem acontece através de uma função bidimensional, cuja representação é f(x,y). Nessa função, x e y são coordenadas em um plano e a amplitude de f em qualquer ponto desse plano é conhecida como intensidade. Caso as quantidades de x, y e os valores de intensidade de f sejam finitas e discretas, a imagem será definida como digital. Além disso, a composição de uma imagem digital é um número finito de elementos cujas localizações e valores são particulares para um pixel \cite{GONZALES}.

Segundo \citeonline{GONZALES}, existem passos fundamentais que devem ser seguidos durante o processamento digital de imagens, sendo elas:


\begin{itemize}
	\item \textbf{Aquisição de Imagem}: é a primeira etapa do processo e envolve o recebimento de imagens em formato digital. Também pode haver a necessidade de um pré-processamento para adequar a imagem ao sistema que a analisará;
	
	\item \textbf{Filtragem e Realce de Imagens}: esta etapa consiste em manipular uma imagem para que ela se torne mais apropriada para o processamento de um sistema específico. É importante frisar que esta fase varia de acordo com as necessidades de cada contexto;
	
	\item \textbf{Restauração de Imagens}: esta área também trata do aprimoramento visual de imagens. No entanto, há uma objetividade maior aqui, tendo em vista que seus métodos de aplicação são oriundos da matemática ou estatística;
	
	\item \textbf{Processamento de Imagens Coloridas}: a cor pode ser um importante fator descritivo de determinado objeto, ou seja, o sistema que puder fazer uso desse artifício pode vir a ser mais eficiente no processo de identificação;
	
	\item \textbf{Extração de Características}: também conhecida como processamento morfológico, essa etapa é responsável pela extração de componentes cuja importância é vital para a representação dos atributos da imagem;
	
	
	\item \textbf{Reconhecimento de Objetos}: da mesma forma que um humano é capaz de identificar objetos com o sentido da visão, uma máquina também pode ser capaz de realizar essa mesma identificação. No entanto, isso é apenas possível por meio da codificação de todas as etapas do processamento de imagens \cite{JAIN};
\end{itemize}


Dito isso, é importante elucidar sobre um aspecto crucial para o desenvolvimento da acurácia do reconhecimento, que é o \textit{dataset}. Essa tecnologia consiste em um grande aglomerado de dados que servirão para a realização de análises. Nessa coleção de dados, existem alguns que serão utilizados pelo sistema como uma referência positiva, para que seja possível deliberar se determinado objeto de análise poderá ser classificado como objeto de interesse. Enquanto isso, as referências negativas servirão para que o sistema possa saber quais aspectos ignorar no processo de análise \cite{JAIN}.

As características de uma imagem deverão ser avaliadas individualmente assim que a fase de reconhecimento for iniciada. Primeiramente, o sistema irá verificar se a imagem possui certo grau de características candidatas a serem parte do objeto de interesse. Se esse resultado for positivo, a imagem será comparada com as do \textit{dataset}. Dessa forma, se as comparações forem válidas, a imagem será classificada como um objeto de interesse \cite{JAIN}.

\subsection{OpenCV}

De acordo com a documentação \citeonline{OPENCV2024}, a OpenCV é uma sigla cujo significado é biblioteca de visão computacional e de código aberto. Essa ferramenta é gratuita, algo que a torna ideal para o desenvolvimento de projetos acadêmicos. Além do mais, ela é amplamente utilizada em \textit{softwares} que aplicam o aprendizado de máquina. 

A biblioteca OpenCV consiste em cinco aspectos fundamentais \cite{BRADSKI2008}:

\begin{itemize}
	\item \textbf{CV}: esse componente possui o objetivo de realizar o processamento de imagens através da visão computacional;
	
	\item \textbf{MLL}: esse componente é responsável pelo aprendizado de máquina, ou seja, ele irá executar modelos treinados e manipular as saídas por meio dos parâmetros definidos;
	
	\item \textbf{HighGUI}: esse componente trata das questões relacionadas a imagens e vídeos. Além do mais, ele possui uma funcionalidade de geração de janelas de visualzação das mídias que serão adicionadas ao código;
	
	\item \textbf{CXCore}: esse componente possui a responsabilidade de englobar todos os aspectos citados em uma apresentação simples e sucinta para que o desenvolvedor possa ter uma compreensão mais adequada;
	
	\item \textbf{CvAux}: permite que o programador utilize funções de reconhecimento facial e reconhecimento de gestos.
	
	
	
\end{itemize}



\section{Inteligência Artificial}
A \sigla{IA}{Inteligência Artificial} é um ramo das ciências da computação cujo objetivo é desenvolver sistemas de computadores capazes de pensar e agir como seres humanos. Essa tecnologia é capaz de desenvolver uma série de ferramentas capazes de aprimorar a produção nas mais diversas áreas do trabalho humano, como por exemplo: extração e processamento de dados, automação de processos, etc \cite{CARVALHO}. 

Dessa forma, percebe-se a evolução que a IA é capaz de realizar diante de algoritmos convencionais tendo em vista que eles apenas leem e executam as linhas sequenciais de um código, ou seja, não são capazes de aprender de nenhuma forma. Portanto, sua aplicabilidade é extremamente limitada \cite{SICHMAN}.

Anteriormamente à IA, o ser humano era o único responsável pelo aprendizado e desenvolvimento de soluções para problemas complexos. No entanto, a inteligência artificial surge como uma alternativa para essa realidade \cite{SICHMAN}.

\subsection{Aprendizado de Máquina}

A Inteligência Artificial (IA) possui uma ramificação nomeada de \sigla{AM}{Aprendizado de Máquina} cujo foco é utilizar grandes quantidades de dados para criar e treinar modelos. Esses modelos, por sua vez, simulam o comportamento humano de resolução de problemas complexos que necessitam de interpretações para serem solucionados, ou seja, um algoritmo convencional não tem como resolvê-los \cite{SMOLA}. 

De acordo com \citeonline{DEISENROTH}, o cerne do aprendizado de máquina gira em torno de dados, modelos e processamento. Os dados possuem uma característica basilar para o AM, já que são eles os responsáveis pela etapa crucial de treinamento. Os modelos, por sua vez, são responsáveis por lidar com situações não apresentadas no \textit{dataset}, ou seja, aqui há a etapa de aprendizado. 

Além do mais, segundo \citeonline{agrawal2020}, o AM possui dois tipos de variáveis vitais para o aprendizado do modelo: os hiperparâmetros e os parâmetros. O primeiro é de caráter manual, pois é necessário determiná-los previamente em relação ao treinamento. O segundo é volátil, uma vez que o próprio modelo é incumbido da responsabilidade de alterá-los à medida que novas informações vão sendo alimentadas.

\subsection{Redes Neurais Artificiais}
De acordo com \citeonline{HAYKIN}, o \sigla{RNA}{Redes Neurais Artificiais} são estudadas e aplicadas pelo fato de que o cérebro humano é capaz de processar informações de forma muito mais eficiente do que um computador por causa das propriedades de complexidade, não-linearidade e paralelismo presentes no cérebro humano. Portanto, um sistema de aprendizado possui muito a ganhar caso consiga reproduzir tal estrutura. 

Além do mais, as habilidade de generalização é outro fator que aumenta consideravelmente o poder computacional de uma RNA. A generalização é a capacidade de fornecer saídas adequadas para entradas que não estavam presente no \textit{dataset} utilizado para treinar o sistema \cite{HAYKIN}. 

No entanto, as redes neurais não são capazes de fornecer resultados trabalhando isoladamente. Elas precisam ser integradas em um sistema maior. Isso acontece da seguinte forma: um problema complexo e dividido em várias tarefas menores e simples, e então grupos de subtarefas serão entregues para redes neurais cuja especialização mais se assemelha às necessidades da tarefa \cite{HAYKIN}.

\subsubsection{Redes Neurais Profundas}
Embora Redes Neurais Profundas (RNP) sejam semelhantes à Redes Neurais Artificiais, há um acréscimo de camadas empilhadas que as diferencia, como ilustrado na figura \ref{fig:ia}.

\begin{figure}[H]
	\centering
	\caption{Rede Neural Simples e Rede Neural Profunda}
	\includegraphics[width=0.8\textwidth]{images/ia/figura6.png}
	\caption*{\textbf{Fonte: Adaptado de \citeonline{BOHANI}.}} 
	\label{fig:ia}
\end{figure}

Em relação à essas camadas adicionais, quanto mais delas existirem na RNP, mais complexo o sistema será, mais recursos computacionais precisarão ser utilizados e mais tempo será necessário para treinar o modelo \cite{SUBASI202091}. 

De acordo com \citeonline{MOHANASUNDARAM2019139}, cada camada irá trabalhar com características diferentes baseadas na saída da camada anterior. Isso significa que, quanto mais se avançar na rede, mais complexas serão as características que as camadas reconhecerão tendo em vista que elas se rearranjam e aprendem com as características das camadas anteriores. A vantagem desse processo é que as redes conseguem modelar relações não lineares e complexas, algo que permite o tratamento de dados não rotulados e não estruturados. 

Portanto, nota-se como as redes neurais profundas são capazes de coletar dados brutos, não rotulados, desestruturados e ainda conseguir agrupá-los e realizar o processamento deles \cite{MOHANASUNDARAM2019139}. 


\subsubsection{Redes Neurais Convolucionais}
De acordo com \citeonline{VARGAS2016}, uma \sigla{RNC}{Rede Neural Convolucional} nacional é uma variação das Redes Neurais Profundas cujo funcionamento é inspirado no processamento biológico de dados visuais. Ademais, semelhantemente a outros métodos da visão computacional, uma RNC também aplica filtros em dados visuais ao mesmo tempo que armazena os relacionamentos de vizinhança entre os \textit{pixels} da imagem com o decorrer do processamento. Segundo \citeonline{ZHANG2018146}, esse é o modelo mais utilizado de RNP em aprendizado de características para classificação e reconhecimento de imagens em grande escala.

O funcionamento de uma RNC é dividido em três etapas principais, que são: a convolução, subamostragem e classificação. \cite{ZHANG2018146}. A convolução, por sua vez, necessita de componentes básicos para funcionar adequadamente, que são: dados de entrada, filtros e mapas de características.

Segundo \citeonline{Alves2018}, as entradas da convolução são consideradas como matrizes tridimensionais cujas duas primeiras dimensões são a altura e a largura da imagem, enquanto a profundidade da terceira dimensão é definida por quantos canais de cores a imagem tem. Por exemplo: se determinada imagem seguir o padrão RGB, a profundidade da terceira dimensão será de três canais. 

Já o filtro, é uma matriz bidimensional com altura e largura menores que as da da entrada cuja função é percorrer a imagem para assimilar as principais características. Ela percorre a imagem de acordo com uma \textit{stride}, que são os saltos feitos pelo filtro para se locomover. Quando todo o trajeto tiver sido percorrido, é gerado um mapa de características, que será a primeira\textit{ hidden layer} \cite{Alves2018}. Dessa forma, à cada convolução, a RNC amplia sua complexidade e identifica trechos maiores da mídia visual que foi fornecida como entrada. Isso significa que as primeiras camadas se concentram em aspectos simples, enquanto as camadas convolucionais finais irão reconhecer características mais complexas \cite{IBM2024}.

Logo em seguida, ocorre a subamostragem (\textit{subsampling}). Ela irá simplificar a saída da camada anterior através de uma matriz bidimensional que irá percorrer toda a saída. À media que essa matriz se locomove, ela escolhe o maior valor dos trechos percorridos e vai gerando outra matriz formada apenas pelos maiores valores. Isso resulta em uma generalização que irá consumir menos recursos computacionais nas etapas seguintes e impede o \textit{overfitting}, que acontece quando um modelo de aprendizado de máquina se adapta excelentemente a um conjunto de dados, mas não funciona adequadamente com dados novos. 

Por fim, a classificação ocorre na camada totalmente conectada através da combinação das características assimiladas pelas camadas anteriores \cite{IBM2024}.

Para ilustrar melhor esse procedimento, a Figura \ref{fig:rnc} abaixo mostra a estrutura de uma das primeiras Redes Neurais Convolucionais:

\begin{figure}[H]
	\centering
	\caption{Arquitetura da LeNet-5, uma Rede Neural Convolucional}
	\includegraphics[width=0.9\textwidth]{images/ia/rnc.png}
	\caption*{\textbf{Fonte: \citeonline{lecun1998gradient}.}} 
	\label{fig:rnc}
\end{figure}

Como pode ser visto na imagem, uma matriz com vários valores percorre a imagem de entrada e quais serão esses valores depende exclusivamente do tipo de resultado desejado. A partir disso, os valores da matriz serão multiplicados por cada número que representa o \textit{pixel}, os resultados das multiplicações serão somados e a somatória de todo esse processo ocupará um pixel da imagem de saída. Isso é repetido até a imagem inteira ser percorrida e um \textit{feature map} ser gerado \cite{kumar2025basiccnn}. 

Com isso, o procedimento de \textit{subsampling} começa 
para reduzir as dimensões do \textit{feature map} ao mesmo tempo que valores relevantes são mantidos com o objetivo de generalizar as informações importantes para o aprendizado do modelo, algo que impede o problema de \textit{overfitting}, que ocorre quando um modelo se adapta demais a uma imagem específica e não funciona bem com outros objetos de interesse da mesma classificação \cite{kumar2025basiccnn}.


Logo em seguida, as etapas de \textit{full conection} realizam a classificação com base nas características relevantes extraídas. Esse procedimento é feito da seguinte forma: as matrizes de cada \textit{feature map} são achatadas para se tornarem unidimensionais e são transformadas em um único grande vetor \cite{kumar2025basiccnn}. 

Os valores desse vetor são processados para que as características sejam aprendidas e associadas a probabilidades para cada classe de interesse \cite{kumar2025basiccnn}. 



\subsubsection{Segmentação de Instância}

De acordo com \citeonline{abdulla2018}, segmentação de instância é o processo de identificar o contorno de um objeto no nível dos \textit{pixels}. 

Primeiramente, ocorre a classificação, ou seja, percebe-se que objetos de determinada classe estão presentes na imagem. Logo após, ocorre a segmentação de semântica cujo objetivo é identificar todos os \textit{pixels} que pertencem à classe de interesse. Depois, a detecção de objetos nota a presença de sete instâncias, mas ainda não consegue diferenciar os \textit{pixels} que se sobrepõem. Por fim, a segmentação de instância é capaz de discernir os contornos de cada objeto, ou seja, o problema de sobreposição foi solucionado. Esse procedimento está descrito na Figura \ref{fig:segmenta}.


\begin{figure}[H]
	\centering
	\caption{Etapas da Segmentação de Instância}
	\includegraphics[width=0.9\textwidth]{images/ia/segmenta.png}
	\caption*{\textbf{Fonte: \citeonline{abdulla2018}{}.}} 
	\label{fig:segmenta}
\end{figure}

\subsubsection{R-CNN}

De acordo com \citeonline{Yenidun2025}, a CNN utiliza uma matriz que percorre uma imagem inteira até encontrar um objeto de interesse. Tendo em vista que esse processo é pouco eficiente e exige muitos recursos computacionais, a \textit{Region-based Convolutional Neural Networks} (R-CNN) aparece como uma solução para otimizar esse busca a partir de determinações das regiões mais prováveis que o objeto irá aparecer. 

Dessa forma, a R-CNN possui 4 principais etapas:


\begin{itemize}
	\item \textbf{Proposta de Região}: um conjunto de propostas de regiões é gerado cada uma delas funciona como uma matriz que pode ou não conter objetos de interesse ;
	
	\item \textbf{Extração de Características}: cada região é proposta é redimensionada para um tamanho fixo porque um classificador de rede neural necessita de dimensões padronizadas;
	
	\item \textbf{Classificação}: verificar se há objetos de interesse dentro de cada região e classificá-los de acordo com suas classes caso existam;
	
	\item \textbf{Regressão de caixa delimitadora}: as matrizes que possuírem objetos de interesse dentro delas serão redimensionadas para que se enquadrem adequadamente aos limites dos objetos.
\end{itemize}




\subsubsection{Mask R-CNN}
O Mask R-CNN, por sua vez, é uma evolução do R-CNN porque possui duas características adicionais: uma rede treinável de proposta de região e segmentação de instância \cite{Yenidun2025}. 

Dessa forma, a rede aprenderá quais são as regiões mais prováveis de conter objetos de interesse, enquanto a segmentação de instância para definir os contornos dos objetos ao nível do pixel, algo que facilita a compreensão de objetos que se sobrepõem \cite{Yenidun2025}. 

\subsubsection{\textit{COCOEvaluator}}
A avaliação de modelos de aprendizado de máquina é um procedimento que transforma pares de entradas e saídas em métricas agregadas. Dessa forma, é possível quantificar a eficiência da execução de um modelo. Um método que realiza esse tipo de tarefa é o \textit{COCOEvaluator} porque ele é capaz de calcular a precisão média de caixas delimitadoras e segmentações de instâncias \cite{detectron2}. 

Para conseguir realizar esses cálculos, o COCOEvaluator precisa trabalhar com determinadas medidas. A primeira delas é a \textit{Insertection over Union} (Iou), que é a base para todas as medidas, serve para calcular a proporção entre a área de intersecção e a área da união entre o espaço previsto pelo modelo e a anotação real feita no pré-processamento. Portanto, o resultado ótimo para essa proporção é 1.0 e quanto mais perto desse valor, melhor \citeonline{rosebrock2016iou}. Isso acontece porque um resultado de 1.0 indica que a área prevista está exatamente onde a anotação foi feita. Essa fórmula pode ser visualizada na Figura \ref{fig:formula}.


\begin{figure}[H]
	\centering
	\caption{Fórmula do IoU}
	\includegraphics[width=0.8\textwidth]{images/ia/formula.png}
	\caption*{\textbf{Fonte: \citeonline{rosebrock2016iou}.}} 
	\label{fig:formula}
\end{figure}

Além do mais, as caixas delimitadoras definem o quão bem o modelo consegue desenhar um retângulo ao redor do oócito, enquanto a segmentação verifica o quão bem o modelo desenha uma máscara nos contornos exatos do oócito, ou seja, \textit{pixel} por \textit{pixel}. E, por fim, \textit{Average Precision} (AP), é simplesmente o resultado médio realizado a partir de vários valores diferentes de IoU. Primeiramente, é preciso explicar os termos da tabela para compreênde-la adequadamente \citeonline{rosebrock2016iou}.